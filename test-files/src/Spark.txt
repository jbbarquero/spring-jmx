************************
* Spark Screen cast: 2 *
************************
https://www.youtube.com/watch?v=bWorBGOFBWY&index=1&list=PL-x35fyliRwhKT-NpTKprPW1bkbdDcTTW
************************

Spark

https://spark.apache.org/

Getting Started
Learning Spark is easy whether you come from a Java or Python background:

· Download the latest release — you can run Spark locally on your laptop.
· Read the quick start guide.
· Spark Summit 2014 contained free training videos and exercises.
· Learn how to deploy Spark on a cluster.

> Download: https://spark.apache.org/downloads.html

Spark 1.1.0, released on September 11, 2014 and source code distribution 

~/Applications/spark-1.1.0

README.md ==> Ctrl+F ## Building Spark

$ ./sbt/sbt assembly
Using /usr/lib/jvm/java-7-oracle as default JAVA_HOME.
Note, this will be overridden by -java-home if it is set.
Attempting to fetch sbt
######################################################################## 100,0%
Launching sbt from sbt/sbt-launch-0.13.5.jar
Getting org.scala-sbt sbt 0.13.5 ...

...

[info] 	[SUCCESSFUL ] junit#junit-dep;4.8.2!junit-dep.jar (730ms)
[info] Done updating.
sbt.ResolveException: download failed: io.netty#netty-all;4.0.23.Final!netty-all.jar
	at sbt.IvyActions$.sbt$IvyActions$$resolve(IvyActions.scala:217)
	at sbt.IvyActions$$anonfun$update$1.apply(IvyActions.scala:126)
	at sbt.IvyActions$$anonfun$update$1.apply(IvyActions.scala:125)
	at sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:115)
	at sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:115)
	at sbt.IvySbt$$anonfun$withIvy$1.apply(Ivy.scala:103)
	at sbt.IvySbt.sbt$IvySbt$$action$1(Ivy.scala:48)
	at sbt.IvySbt$$anon$3.call(Ivy.scala:57)
	at xsbt.boot.Locks$GlobalLock.withChannel$1(Locks.scala:98)
	at xsbt.boot.Locks$GlobalLock.xsbt$boot$Locks$GlobalLock$$withChannelRetries$1(Locks.scala:81)
	at xsbt.boot.Locks$GlobalLock$$anonfun$withFileLock$1.apply(Locks.scala:102)
	at xsbt.boot.Using$.withResource(Using.scala:11)
	at xsbt.boot.Using$.apply(Using.scala:10)
	at xsbt.boot.Locks$GlobalLock.ignoringDeadlockAvoided(Locks.scala:62)
	at xsbt.boot.Locks$GlobalLock.withLock(Locks.scala:52)
	at xsbt.boot.Locks$.apply0(Locks.scala:31)
	at xsbt.boot.Locks$.apply(Locks.scala:28)
	at sbt.IvySbt.withDefaultLogger(Ivy.scala:57)
	at sbt.IvySbt.withIvy(Ivy.scala:98)
	at sbt.IvySbt.withIvy(Ivy.scala:94)
	at sbt.IvySbt$Module.withModule(Ivy.scala:115)
	at sbt.IvyActions$.update(IvyActions.scala:125)
	at sbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1223)
	at sbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1221)
	at sbt.Classpaths$$anonfun$doWork$1$1$$anonfun$74.apply(Defaults.scala:1244)
	at sbt.Classpaths$$anonfun$doWork$1$1$$anonfun$74.apply(Defaults.scala:1242)
	at sbt.Tracked$$anonfun$lastOutput$1.apply(Tracked.scala:35)
	at sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1246)
	at sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1241)
	at sbt.Tracked$$anonfun$inputChanged$1.apply(Tracked.scala:45)
	at sbt.Classpaths$.cachedUpdate(Defaults.scala:1249)
	at sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1214)
	at sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1192)
	at scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)
	at sbt.$tilde$greater$$anonfun$$u2219$1.apply(TypeFunctions.scala:42)
	at sbt.std.Transform$$anon$4.work(System.scala:64)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18)
	at sbt.Execute.work(Execute.scala:244)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:30)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[error] (core/*:update) sbt.ResolveException: download failed: io.netty#netty-all;4.0.23.Final!netty-all.jar
[error] Total time: 388 s, completed Nov 14, 2014 1:12:59 PM
:~/Applications/spark-1.1.0$ 


No need for scala now


Let's try with ~/Applications/spark-1.1.0-bin-hadoop2.4

OK

Spark is built on Scala 2.10. To build Spark and its example programs, run:

    ./sbt/sbt assembly

(You do not need to do this if you downloaded a pre-built package.)

## Interactive Scala Shell

The easiest way to start using Spark is through the Scala shell:

    ./bin/spark-shell

Try the following command, which should return 1000:

    scala> sc.parallelize(1 to 1000).count()

And let's try to read and count README.md as it appears in the video

************************
* Spark Screen cast: 2 *
************************
https://www.youtube.com/watch?v=Dbqe_rv-NJQ&list=PL-x35fyliRwhKT-NpTKprPW1bkbdDcTTW&index=2
************************


http://ampcamp.berkeley.edu/big-data-mini-course-home/

************************
* Spark Screen cast: 3 *
************************
https://www.youtube.com/watch?v=TtvxKzO9jXE&list=PL-x35fyliRwhKT-NpTKprPW1bkbdDcTTW&index=3
************************
